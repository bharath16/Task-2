{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\Bharathwaj\\\\Documents\\\\Tiliter\\\\data\\\\video_1.mp4\n"
     ]
    }
   ],
   "source": [
    "file_path = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "fps = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "monochrome = bool(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoCapture 000001D886286690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monochrome = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(monochrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\Bharathwaj\\\\Documents\\\\Tiliter\\\\data\\\\video_1.mp4\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    if ret == True:\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "        cv2.imshow('Frame',gray)            \n",
    "        if cv2.waitKey(25) or 0xFF == ord('q'):\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if monochrome == True:\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame=cap.read()\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "        if ret == True:\n",
    "            cv2.imshow('Frame',gray)            \n",
    "            if cv2.waitKey(25) or 0xFF == ord('q'):\n",
    "                break\n",
    "            if cv2.waitKey(1) or 0xFF == ord('p'):\n",
    "                cv2.waitKey(-1)\n",
    "                if cv2.waitkey(1) or 0xFF == ord('b'):\n",
    "                    cv2.set(cv2.CV_CAP_PROP_POS_FRAMES(2, previous_frame))\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('Frame', frame)\n",
    "            if cv2.waitKey(25) or 0xFF == ord('q'):\n",
    "                break\n",
    "            if cv2.waitKey(1) or 0xFF == ord('p'):\n",
    "                cv2.waitKey(-1)\n",
    "                if cv2.waitkey(1) or 0xFF == ord('b'):\n",
    "                    cv2.set(cv2.CV_CAP_PROP_POS_FRAMES(2))\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pixellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (semantic.py, line 222)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Bharathwaj\\Anaconda3\\envs\\data_env\\lib\\site-packages\\pixellib\\semantic.py\"\u001b[1;36m, line \u001b[1;32m222\u001b[0m\n\u001b[1;33m    print(f\"Processed {counter} frames in {end-start:.1f} seconds\")\u001b[0m\n\u001b[1;37m                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pixellib\n",
    "from pixellib.semantic import semantic_segmentation\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"C:\\\\Users\\\\Bharathwaj\\\\Documents\\\\Tiliter\\\\data\\\\video_1.mp4\")\n",
    "\n",
    "segment_video = semantic_segmentation()\n",
    "segment_video.load_pascalvoc_model(\"mask_rcnn_coco.h5\")\n",
    "segment_video.process_camera_pascalvoc(capture,  overlay = True, frames_per_second= 30, output_video_name=\"output_video.mp4\", show_frames= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoCapture 000002397BC0E3B0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\Bharathwaj\\\\Documents\\\\Tiliter\\\\data\\\\video_1.mp4\")\n",
    "\n",
    "#initialize the cv2- background subtractor for KNN and MOG2\n",
    "BS_knn = cv2.createBackgroundSubtractorKNN()\n",
    "BS_MOG2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read() # frame reader\n",
    "    if ret == True:\n",
    "        #extract Knn method for foreground mask\n",
    "        \n",
    "        knn_foregmask = BS_knn.apply(frame)\n",
    "        cv2.imshow('KNN Method', knn_foregmask)\n",
    "\n",
    "        #extract MOG2 method for foreground mask\n",
    "        mog2_foregmask = BS_MOG2.apply(frame)\n",
    "        cv2.imshow('MOG2 Method', mog2_foregmask)   \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "#release video capture\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-iw3y3ir8\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4161f1e7a4fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frame2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m#extract the foreground mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mforegmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-iw3y3ir8\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\Bharathwaj\\\\Documents\\\\Tiliter\\\\data\\\\video_1.mp4\")\n",
    "\n",
    "#reading then frame 1\n",
    "ret,frame1 = cap.read()\n",
    "cv2.imshow('Frame1',frame1)\n",
    "\n",
    "#reading the frame 2\n",
    "while(cap.isOpened()):\n",
    "     \n",
    "    ret,frame2 = cap.read()\n",
    "    \n",
    "    cv2.imshow('Frame2',frame2)\n",
    "    #extract the foreground mask\n",
    "    foregmask = cv2.absdiff(frame1, frame2)\n",
    "\n",
    "    #apply the threshold\n",
    "    _, thresh = cv2.threshold(foregmask,10,255,cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Foreground Mask', thresh)\n",
    "    \n",
    "    frame1 = frame2\n",
    "\n",
    "    colr = cv2.cvtColor(thresh,cv2.COLOR_RGB2GRAY)\n",
    "    cv2.imshow('color', colr)\n",
    "    #wait until any key pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "#release video capture\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghcircles/py_houghcircles.html\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the image\n",
    "img = cv2.imread('E:\\\\FOTOS\\\\opencv\\\\opencv_logo.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# detect circles\n",
    "gray = cv2.medianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 5)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=50, minRadius=0, maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "# draw mask\n",
    "mask = np.full((img.shape[0], img.shape[1]), 0, dtype=np.uint8)  # mask is only \n",
    "for i in circles[0, :]:\n",
    "    cv2.circle(mask, (i[0], i[1]), i[2], (255, 255, 255), -1)\n",
    "\n",
    "# get first masked value (foreground)\n",
    "fg = cv2.bitwise_or(img, img, mask=mask)\n",
    "\n",
    "# get second masked value (background) mask must be inverted\n",
    "mask = cv2.bitwise_not(mask)\n",
    "background = np.full(img.shape, 255, dtype=np.uint8)\n",
    "bk = cv2.bitwise_or(background, background, mask=mask)\n",
    "\n",
    "# combine foreground+background\n",
    "final = cv2.bitwise_or(fg, bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if 0xFF == ord('b'):\n",
    "                    cv2.set(cv2.CV_CAP_PROP_POS_FRAMES(2, previous_frame))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
